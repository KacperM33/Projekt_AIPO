{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d249e1",
   "metadata": {},
   "source": [
    "# Ekstrakcja szkieletu (pose estimation)\n",
    "\n",
    "Do realizacji projektu wybrano framework **MMPose** (https://github.com/open-mmlab/mmpose) z ekosystemu OpenMMLab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a8773",
   "metadata": {},
   "source": [
    "## Wczytanie sekwencji wideo / klatek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a039df1",
   "metadata": {},
   "source": [
    "### Wstępne ustawienia (detektor, pose estimator)\n",
    "\n",
    "- **Detektor**: Faster R-CNN\n",
    "- **Pose estimator**: HRNet-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ustawienia detektora\n",
    "detector_cfg = \"../mmpose/demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py\"\n",
    "detector_chkp = \"../mmpose/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\"\n",
    "\n",
    "# ustawienia pose estimatora\n",
    "pose_cfg = \"../mmpose/model_configs/td-hm_hrnet-w32_8xb64-210e_coco-256x192.py\"\n",
    "pose_chkp = \"../mmpose/checkpoints/td-hm_hrnet-w32_8xb64-210e_coco-256x192-81c58e40_20220909.pth\"\n",
    "\n",
    "# plik ze skryptem\n",
    "script = \"../mmpose/demo/topdown_demo_with_mmdet.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec4912",
   "metadata": {},
   "source": [
    "### Wczytanie i przetworzenie wszystkich sekwencji klatek na pliki wideo (mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed3e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Konwertowanie: 100%|██████████| 70/70 [04:08<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zakończono konwersję sekwencji klatek do wideo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm # pasek postępu\n",
    "\n",
    "# ścieżka do sekwencji klatek (?)\n",
    "frames_folder = f\"../UR_fall_det/frames\"\n",
    "# folder wyjściowy (do zapisu wyników)\n",
    "output_folder = \"../UR_fall_det/videos\"\n",
    "\n",
    "# tworzenie folderu wyjściowego jeśli nie istnieje\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# filtrowanie aby mieć katalogi z klatkami\n",
    "folders = [f for f in os.listdir(frames_folder) if os.path.isdir(os.path.join(frames_folder, f))]\n",
    "# sortowanie\n",
    "folders = sorted(folders)\n",
    "\n",
    "# pętla przetwarzająca\n",
    "for folder_name in tqdm(folders, desc=\"Konwertowanie\"):\n",
    "    \n",
    "    input_folder_path = os.path.join(frames_folder, folder_name)\n",
    "    output_video_path = os.path.join(output_folder, f\"{folder_name}-vis.mp4\")\n",
    "\n",
    "    # Wzorzec: \"fall-01-cam0-rgb-%03d.png\" (%03d oznacza 3 cyfry: 001, 002...)\n",
    "    file_pattern = f'{folder_name}-%03d.png' \n",
    "\n",
    "    input_pattern_path = os.path.join(input_folder_path, file_pattern)\n",
    "\n",
    "    # FFMPEG\n",
    "    cmd = (\n",
    "        f'ffmpeg -y -framerate 30 '\n",
    "        f'-i \"{input_pattern_path}\" '\n",
    "        f'-c:v libx264 -pix_fmt yuv420p '\n",
    "        f'\"{output_video_path}\"'\n",
    "    )\n",
    "\n",
    "    exit_code = os.system(cmd)\n",
    "\n",
    "    if exit_code != 0:\n",
    "        print(f\"\\nBŁĄD przy folderze {folder_name}.\")\n",
    "\n",
    "print(\"\\nZakończono konwersję sekwencji klatek do wideo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d5dce",
   "metadata": {},
   "source": [
    "### Użycie detektora MMPose do wyznaczenia keypointów i bounding boxów dla każdej klatki wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8825ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 70 plików wideo do przetworzenia.\n",
      "\n",
      "Przechodzę do detekcji keypointów w MMPose...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie wideo:  33%|███▎      | 23/70 [34:16<59:52, 76.44s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BŁĄD przy wideo adl-23-cam0-rgb-vis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Przetwarzanie wideo: 100%|██████████| 70/70 [1:27:17<00:00, 74.83s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zakończono detekcję wideo z sukcesem.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ścieżka do filmów\n",
    "input_videos_folder = \"../UR_fall_det/videos\"\n",
    "# folder wyjściowy\n",
    "output_videos_folder = \"../results\"\n",
    "\n",
    "# filtrowanie aby mieć pliki .mp4\n",
    "videos = [v for v in os.listdir(input_videos_folder) if v.endswith('.mp4')]\n",
    "videos = sorted(videos)\n",
    "\n",
    "print(f\"Znaleziono {len(videos)} plików wideo do przetworzenia.\")\n",
    "\n",
    "print(\"\\nPrzechodzę do detekcji keypointów w MMPose...\")\n",
    "\n",
    "# pętla po plikach\n",
    "for video_file in tqdm(videos, desc=\"Przetwarzanie wideo\"):\n",
    "\n",
    "    input_video_path = os.path.join(input_videos_folder, video_file)\n",
    "\n",
    "    video_name_only = os.path.splitext(video_file)[0]\n",
    "    output_folder_path = os.path.join(output_videos_folder, video_name_only)\n",
    "\n",
    "    command = (\n",
    "        f'{sys.executable} '        # Odpowiednik 'python' (gwarantuje użycie tego samego środowiska)\n",
    "        f'{script} '                # skrypt\n",
    "        f'{detector_cfg} '          # plik config detektora\n",
    "        f'{detector_chkp} '         # checkpoint detektora\n",
    "        f'{pose_cfg} '              # plik config pose estimatora\n",
    "        f'{pose_chkp} '             # checkpoint pose estimatora\n",
    "        f'--input \"{input_video_path}\" '               # wideo wejściowe\n",
    "        f'--output-root \"{output_folder_path}\" '       # folder wynikowy\n",
    "        f'--save-predictions '                         # aby zapisać predykcje w formacie JSON\n",
    "        f'--draw-bbox '                                # aby rysować bounding boxy\n",
    "        f'--device cuda:0'                             # wymuszenie GPU (można zakomentować)\n",
    "    )\n",
    "\n",
    "    process = os.system(command)\n",
    "\n",
    "    if process != 0:\n",
    "        print(f\"\\nBŁĄD przy wideo {video_name_only}.\")\n",
    "\n",
    "print(\"\\nZakończono detekcję wideo z sukcesem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f545b",
   "metadata": {},
   "source": [
    "## Wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e89ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odtwarzam wideo za pomocą OpenCV: fall-17-cam0-rgb-vis\n",
      "Naciśnij 'q' na klawiaturze (w oknie wideo), aby zamknąć.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from IPython.display import Video\n",
    "import cv2\n",
    "\n",
    "# ścieżka do filmów z wyznaczonymi keypointami\n",
    "results_video_path = \"../results/\"\n",
    "\n",
    "# filtrowanie aby mieć katalogi z wideo\n",
    "results_videos = [r for r in os.listdir(results_video_path) if os.path.isdir(os.path.join(results_video_path, r))]\n",
    "# sortowanie\n",
    "results_videos = sorted(results_videos)\n",
    "\n",
    "# wybieramy losowe wideo folderu\n",
    "# można też po prostu podać ścieżke do konkretnego wideo\n",
    "selected_video = random.choice(results_videos) # <-- można zamienić na np \"fall-01-cam0-rgb-vis.mp4\"\n",
    "\n",
    "# pełna ścieżka\n",
    "full_video_path = os.path.join(results_video_path, selected_video)\n",
    "full_video_path = os.path.join(full_video_path, f\"{selected_video}.mp4\")\n",
    "\n",
    "# print(f\"Otwieram w systemowym odtwarzaczu: {selected_video}\")\n",
    "# # Działa tylko na Windows:\n",
    "# os.startfile(full_video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(full_video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Błąd: Nie można otworzyć pliku wideo.\")\n",
    "else:\n",
    "    print(f\"Odtwarzam wideo za pomocą OpenCV: {selected_video}\")\n",
    "    print(\"Naciśnij 'q' na klawiaturze (w oknie wideo), aby zamknąć.\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Wyświetlanie klatki w oknie \"Podgląd\"\n",
    "            cv2.imshow(f'{selected_video}', frame)\n",
    "            \n",
    "            # Czekaj 25ms (ok. 40 FPS) i sprawdź czy wciśnięto 'q'\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projekt_aipo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
